# neural_network

Implémentation d'un réseau de neurones artificiels utilisant la fonction d'activation ReLU (Rectified Linear Unit) pour résoudre des problèmes de classification.

Plus précisément, le réseau de neurones est initialisé avec un certain nombre de couches (ici, une couche d'entrée, une couche cachée et une couche de sortie) et des poids et des biais aléatoires. L'algorithme effectue ensuite une propagation avant des entrées à travers le réseau pour calculer la sortie correspondante. Ensuite, il effectue une rétropropagation de l'erreur pour mettre à jour les poids et les biais du réseau de manière à réduire l'erreur lors de la prochaine propagation avant.
